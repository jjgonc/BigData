{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bd1715-889a-4e4e-99fa-cc88f009bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a1b2228-ad9a-4e48-8925-2e986190e0ca",
   "metadata": {},
   "source": [
    "## Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724437d3-0c7f-43c5-8707-a039d9a99887",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/HPI_master.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "data_json = pd.DataFrame(json_data)\n",
    "\n",
    "# Carregar o dataset CSV - Population size\n",
    "data_csv_ps = pd.read_csv(\"../datasets/US_Population.csv\")\n",
    "data_csv_ps = pd.DataFrame(data_csv_ps)\n",
    "\n",
    "# Carregar o dataset CSV - Population size\n",
    "data_csv_fb = pd.read_csv(\"../datasets/cu.data.11.USFoodBeverage.csv\")\n",
    "data_csv_fb = pd.DataFrame(data_csv_fb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cdd734-e3ff-4b52-96dd-943191e78667",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Visualizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a881d113-6f6d-4d0b-8470-eacba8626d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpi_type</th>\n",
       "      <th>hpi_flavor</th>\n",
       "      <th>frequency</th>\n",
       "      <th>level</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>yr</th>\n",
       "      <th>period</th>\n",
       "      <th>index_nsa</th>\n",
       "      <th>index_sa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>2</td>\n",
       "      <td>100.91</td>\n",
       "      <td>100.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>101.30</td>\n",
       "      <td>100.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>4</td>\n",
       "      <td>101.69</td>\n",
       "      <td>100.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>5</td>\n",
       "      <td>102.32</td>\n",
       "      <td>101.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hpi_type     hpi_flavor frequency                   level   \n",
       "0  traditional  purchase-only   monthly  USA or Census Division  \\\n",
       "1  traditional  purchase-only   monthly  USA or Census Division   \n",
       "2  traditional  purchase-only   monthly  USA or Census Division   \n",
       "3  traditional  purchase-only   monthly  USA or Census Division   \n",
       "4  traditional  purchase-only   monthly  USA or Census Division   \n",
       "\n",
       "                    place_name place_id    yr  period  index_nsa index_sa  \n",
       "0  East North Central Division   DV_ENC  1991       1     100.00    100.0  \n",
       "1  East North Central Division   DV_ENC  1991       2     100.91   100.96  \n",
       "2  East North Central Division   DV_ENC  1991       3     101.30   100.91  \n",
       "3  East North Central Division   DV_ENC  1991       4     101.69   100.98  \n",
       "4  East North Central Division   DV_ENC  1991       5     102.32   101.36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25764e50-b56a-499c-89d5-de5489bb229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>kids</th>\n",
       "      <th>adults</th>\n",
       "      <th>retired</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1970</td>\n",
       "      <td>1854529</td>\n",
       "      <td>1265548</td>\n",
       "      <td>324277</td>\n",
       "      <td>3444354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1971</td>\n",
       "      <td>1887880</td>\n",
       "      <td>1271008</td>\n",
       "      <td>338190</td>\n",
       "      <td>3497078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1972</td>\n",
       "      <td>1909696</td>\n",
       "      <td>1281943</td>\n",
       "      <td>347762</td>\n",
       "      <td>3539401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1973</td>\n",
       "      <td>1922269</td>\n",
       "      <td>1298573</td>\n",
       "      <td>358937</td>\n",
       "      <td>3579779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1974</td>\n",
       "      <td>1939875</td>\n",
       "      <td>1315835</td>\n",
       "      <td>370791</td>\n",
       "      <td>3626501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_id    state  year     kids   adults  retired      all\n",
       "0         1  Alabama  1970  1854529  1265548   324277  3444354\n",
       "1         1  Alabama  1971  1887880  1271008   338190  3497078\n",
       "2         1  Alabama  1972  1909696  1281943   347762  3539401\n",
       "3         1  Alabama  1973  1922269  1298573   358937  3579779\n",
       "4         1  Alabama  1974  1939875  1315835   370791  3626501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv_ps.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "684e7388-9e68-4a83-9250-4c7ec5b64b8c",
   "metadata": {},
   "source": [
    "#### **Tipos de dados do dataset: `Population Size`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a5708e-7465-4e2f-89c5-60fb1d52c64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2132 entries, 0 to 2131\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   state_id  2132 non-null   int64 \n",
      " 1   state     2132 non-null   object\n",
      " 2   year      2132 non-null   int64 \n",
      " 3   kids      2132 non-null   int64 \n",
      " 4   adults    2132 non-null   int64 \n",
      " 5   retired   2132 non-null   int64 \n",
      " 6   all       2132 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 116.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_csv_ps.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "365eb01d-ba04-4fe3-9d87-f0c9352110e9",
   "metadata": {},
   "source": [
    "#### **Tipos de dados do dataset: `House Price Index`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dceddf7-6782-4613-a6d3-371c0ae0f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hpi_type       object\n",
       "hpi_flavor     object\n",
       "frequency      object\n",
       "level          object\n",
       "place_name     object\n",
       "place_id       object\n",
       "yr              int64\n",
       "period          int64\n",
       "index_nsa     float64\n",
       "index_sa       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60c8aafe",
   "metadata": {},
   "source": [
    "#### **Tipos de dados do dataset: `Food & Beverage`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d36de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145320 entries, 0 to 145319\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   series_id       145320 non-null  object \n",
      " 1   year            145320 non-null  int64  \n",
      " 2   period          145320 non-null  object \n",
      " 3   value           145320 non-null  float64\n",
      " 4   footnote_codes  0 non-null       float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_csv_fb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf92114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M01' 'M02' 'M03' 'M04' 'M05' 'M06' 'M07' 'M08' 'M09' 'M10' 'M11' 'M12'\n",
      " 'M13' 'S01' 'S02' 'S03']\n"
     ]
    }
   ],
   "source": [
    "print(data_csv_fb['period'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b71d0813",
   "metadata": {},
   "source": [
    "#### **Verificar a existência de Missing Values nos Dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e36e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in House Price dataset:\n",
      "hpi_type      0\n",
      "hpi_flavor    0\n",
      "frequency     0\n",
      "level         0\n",
      "place_name    0\n",
      "place_id      0\n",
      "yr            0\n",
      "period        0\n",
      "index_nsa     0\n",
      "index_sa      0\n",
      "dtype: int64\n",
      "Number of nan values in House Price dataset:\n",
      "hpi_type          0\n",
      "hpi_flavor        0\n",
      "frequency         0\n",
      "level             0\n",
      "place_name        0\n",
      "place_id          0\n",
      "yr                0\n",
      "period            0\n",
      "index_nsa         0\n",
      "index_sa      81162\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values in House Price dataset:\")\n",
    "json_MV = data_json.isnull().sum()\n",
    "print(json_MV)\n",
    "\n",
    "print(\"Number of nan values in House Price dataset:\")\n",
    "nan_counts = data_json.apply(lambda x: x.value_counts().get('NaN', 0))\n",
    "\n",
    "# Print the number of \"Nan\" values for each column\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c197d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Population Size dataset:\n",
      "state_id    0\n",
      "state       0\n",
      "year        0\n",
      "kids        0\n",
      "adults      0\n",
      "retired     0\n",
      "all         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values in Population Size dataset:\")\n",
    "populationSize_MV = data_csv_ps.isnull().sum()\n",
    "print(populationSize_MV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b7b2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Population Size dataset:\n",
      "series_id              0\n",
      "year                   0\n",
      "period                 0\n",
      "value                  0\n",
      "footnote_codes    145320\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values in Population Size dataset:\")\n",
    "fb_MV = data_csv_fb.isnull().sum()\n",
    "print(fb_MV)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "627fa9cc-b961-45d6-9742-2039fb3ee8b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Tratamento dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cb5b59e",
   "metadata": {},
   "source": [
    "#### **Remover coluna footnote_codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "403ef291",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_fb.drop(columns=[\"footnote_codes\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c9f9771",
   "metadata": {},
   "source": [
    "#### **Filtrar apenas as colunas com `year` igual ou superior a 1977**\n",
    "Uma vez que nem todos os datasets contêm informação de anos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66d7fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataframes size before]:\n",
      "\n",
      "\n",
      "PS:  state_id    2132\n",
      "state       2132\n",
      "year        2132\n",
      "kids        2132\n",
      "adults      2132\n",
      "retired     2132\n",
      "all         2132\n",
      "dtype: int64 \n",
      "\n",
      "HPI:  hpi_type      121462\n",
      "hpi_flavor    121462\n",
      "frequency     121462\n",
      "level         121462\n",
      "place_name    121462\n",
      "place_id      121462\n",
      "yr            121462\n",
      "period        121462\n",
      "index_nsa     121462\n",
      "index_sa      121462\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"[Dataframes size before]:\\n\\n\")\n",
    "print(\"PS: \", data_csv_ps.count(), \"\\n\")\n",
    "print(\"HPI: \", data_json.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09424a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_ps = data_csv_ps[data_csv_ps['year'] >= 1975]\n",
    "data_csv_fb = data_csv_fb[data_csv_fb['year'] >= 1975]\n",
    "data_json = data_json[data_json['yr'] >= 1975]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "447c2018",
   "metadata": {},
   "source": [
    "Verificar a correção do tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aed5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_json.iterrows():\n",
    "    if row['yr'] < 1975:\n",
    "        print(\"Falha detectada na linha\", index)\n",
    "\n",
    "for index, row in data_json.iterrows():\n",
    "    if row['yr'] < 1975:\n",
    "        print(\"Falha detectada na linha\", index)\n",
    "\n",
    "for index, row in data_json.iterrows():\n",
    "    if row['yr'] < 1975:\n",
    "        print(\"Falha detectada na linha\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b87fd5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpi_type</th>\n",
       "      <th>hpi_flavor</th>\n",
       "      <th>frequency</th>\n",
       "      <th>level</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>yr</th>\n",
       "      <th>period</th>\n",
       "      <th>index_nsa</th>\n",
       "      <th>index_sa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>2</td>\n",
       "      <td>100.91</td>\n",
       "      <td>100.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>101.30</td>\n",
       "      <td>100.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>4</td>\n",
       "      <td>101.69</td>\n",
       "      <td>100.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traditional</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>monthly</td>\n",
       "      <td>USA or Census Division</td>\n",
       "      <td>East North Central Division</td>\n",
       "      <td>DV_ENC</td>\n",
       "      <td>1991</td>\n",
       "      <td>5</td>\n",
       "      <td>102.32</td>\n",
       "      <td>101.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hpi_type     hpi_flavor frequency                   level   \n",
       "0  traditional  purchase-only   monthly  USA or Census Division  \\\n",
       "1  traditional  purchase-only   monthly  USA or Census Division   \n",
       "2  traditional  purchase-only   monthly  USA or Census Division   \n",
       "3  traditional  purchase-only   monthly  USA or Census Division   \n",
       "4  traditional  purchase-only   monthly  USA or Census Division   \n",
       "\n",
       "                    place_name place_id    yr  period  index_nsa index_sa  \n",
       "0  East North Central Division   DV_ENC  1991       1     100.00    100.0  \n",
       "1  East North Central Division   DV_ENC  1991       2     100.91   100.96  \n",
       "2  East North Central Division   DV_ENC  1991       3     101.30   100.91  \n",
       "3  East North Central Division   DV_ENC  1991       4     101.69   100.98  \n",
       "4  East North Central Division   DV_ENC  1991       5     102.32   101.36  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a137358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataframe size after]: PS:  state_id    1872\n",
      "state       1872\n",
      "year        1872\n",
      "kids        1872\n",
      "adults      1872\n",
      "retired     1872\n",
      "all         1872\n",
      "dtype: int64 HPI:  hpi_type      121462\n",
      "hpi_flavor    121462\n",
      "frequency     121462\n",
      "level         121462\n",
      "place_name    121462\n",
      "place_id      121462\n",
      "yr            121462\n",
      "period        121462\n",
      "index_nsa     121462\n",
      "index_sa      121462\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"[Dataframe size after]: PS: \", data_csv_ps.count(), \"HPI: \", data_json.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "964749c0-56f4-403d-8863-9f998d8fec03",
   "metadata": {},
   "source": [
    "#### **Remover a coluna `index_sa`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f89bc6b-623d-44c6-84e2-1c1703e073f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = data_json.drop('index_sa', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0081afcc",
   "metadata": {},
   "source": [
    "#### **Descartar S01, S02, S03, M13 dos valores de `period`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a802ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_fb = data_csv_fb[~data_csv_fb['period'].isin(['M13','S01', 'S02', 'S03'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b183066",
   "metadata": {},
   "source": [
    "#### **Transformar `period` em dados numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "199ef4f2-f8e0-447c-99e4-57a0e715aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         3\n",
       "3         4\n",
       "4         5\n",
       "         ..\n",
       "121457    4\n",
       "121458    1\n",
       "121459    2\n",
       "121460    3\n",
       "121461    4\n",
       "Name: period, Length: 121462, dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_map = {\n",
    "    'M01': 1,\n",
    "    'M02': 2,\n",
    "    'M03': 3,\n",
    "    'M04': 4,\n",
    "    'M05': 5,\n",
    "    'M06': 6,\n",
    "    'M07': 7,\n",
    "    'M08': 8,\n",
    "    'M09': 9,\n",
    "    'M10': 10,\n",
    "    'M11': 11,\n",
    "    'M12': 12,\n",
    "    'M13': 13,\n",
    "    'S01': 14,\n",
    "    'S02': 15,\n",
    "    'S03': 16\n",
    "}\n",
    "\n",
    "data_csv_fb['period'] = data_csv_fb[\"period\"].replace(period_map)\n",
    "\n",
    "data_json['period'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2243a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_fb_filtered = data_csv_fb[data_csv_fb['series_id'] == 'CUSR0000SAF']\n",
    "data_csv_fb_filtered.loc[:, 'value'] = data_csv_fb_filtered.groupby('year')['value'].transform('mean')\n",
    "data_csv_fb_filtered = data_csv_fb_filtered.drop_duplicates(subset='year', keep='first')\n",
    "\n",
    "# Drop the first column and the 'series_id' column\n",
    "data_csv_fb_filtered = data_csv_fb_filtered.drop(columns=[data_csv_fb_filtered.columns[0], 'series_id', 'period'])\n",
    "\n",
    "# Optional: Reset index if desired\n",
    "data_csv_fb_filtered = data_csv_fb_filtered.reset_index(drop=True)\n",
    "\n",
    "# Rename the 'value' column to 'index_food'\n",
    "data_csv_fb_filtered = data_csv_fb_filtered.rename(columns={'value': 'index_food'})\n",
    "\n",
    "# Assign the resulting DataFrame to data_csv_fb\n",
    "data_csv_fb = data_csv_fb_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9187f30f",
   "metadata": {},
   "source": [
    "#### **Extrair `State` da localização no dataset `json` (House Price Index)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41f4dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "state_names = {\n",
    "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
    "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
    "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
    "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
    "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\",\n",
    "    \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \"OH\": \"Ohio\",\n",
    "    \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\",\n",
    "    \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\",\n",
    "    \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\",\n",
    "    \"Alabama\": \"Alabama\", \"Alaska\": \"Alaska\", \"Arizona\": \"Arizona\", \"Arkansas\": \"Arkansas\",\n",
    "    \"California\": \"California\", \"Colorado\": \"Colorado\", \"Connecticut\": \"Connecticut\", \"Delaware\": \"Delaware\",\n",
    "    \"Florida\": \"Florida\", \"Georgia\": \"Georgia\", \"Hawaii\": \"Hawaii\", \"Idaho\": \"Idaho\", \"Illinois\": \"Illinois\",\n",
    "    \"Indiana\": \"Indiana\", \"Iowa\": \"Iowa\", \"Kansas\": \"Kansas\", \"Kentucky\": \"Kentucky\", \"Louisiana\": \"Louisiana\",\n",
    "    \"Maine\": \"Maine\", \"Maryland\": \"Maryland\", \"Massachusetts\": \"Massachusetts\", \"Michigan\": \"Michigan\",\n",
    "    \"Minnesota\": \"Minnesota\", \"Mississippi\": \"Mississippi\", \"Missouri\": \"Missouri\", \"Montana\": \"Montana\",\n",
    "    \"Nebraska\": \"Nebraska\", \"Nevada\": \"Nevada\", \"New Hampshire\": \"New Hampshire\", \"New Jersey\": \"New Jersey\",\n",
    "    \"New Mexico\": \"New Mexico\", \"New York\": \"New York\", \"North Carolina\": \"North Carolina\",\n",
    "    \"North Dakota\": \"North Dakota\", \"Ohio\": \"Ohio\", \"Oklahoma\": \"Oklahoma\", \"Oregon\": \"Oregon\",\n",
    "    \"Pennsylvania\": \"Pennsylvania\", \"Rhode Island\": \"Rhode Island\", \"South Carolina\": \"South Carolina\",\n",
    "    \"South Dakota\": \"South Dakota\", \"Tennessee\": \"Tennessee\", \"Texas\": \"Texas\", \"Utah\": \"Utah\",\n",
    "    \"Vermont\": \"Vermont\", \"Virginia\": \"Virginia\", \"Washington\": \"Washington\", \"West Virginia\": \"West Virginia\",\n",
    "    \"Wisconsin\": \"Wisconsin\", \"Wyoming\": \"Wyoming\", \"Puerto Rico\": \"Puerto Rico\", \"United States\": \"United States\",\n",
    "    \"East North Central Division\": \"East North Central Division\", \"East South Central Division\": \"East South Central Division\",\n",
    "    \"Middle Atlantic Division\": \"Middle Atlantic Division\", \"Mountain Division\": \"Mountain Division\", \"New England Division\": \"New England Division\",\n",
    "    \"South Atlantic Division\": \"South Atlantic Division\", \"West North Central Division\": \"West North Central Division\",\n",
    "    \"West South Central Division\": \"West South Central Division\", \"Pacific Division\": \"Pacific Division\"\n",
    "}\n",
    "\n",
    "\n",
    "# Define the array of values\n",
    "special_names = [\n",
    "    \"Alaska\", \"Alabama\", \"Arkansas\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\",\n",
    "    \"Delaware\", \"East North Central Division\", \"East South Central Division\", \"Middle Atlantic Division\",\n",
    "    \"Mountain Division\", \"New England Division\", \"Pacific Division\", \"South Atlantic Division\",\n",
    "    \"West North Central Division\", \"West South Central Division\", \"Florida\", \"Georgia\", \"Hawaii\", \"Iowa\", \"Idaho\",\n",
    "    \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\",\n",
    "    \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\",\n",
    "    \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n",
    "    \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"United States\", \"Utah\",\n",
    "    \"Virginia\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "def extract_state(place_name):\n",
    "    if place_name not in special_names:\n",
    "        state = re.findall(r'\\b([A-Z]{2})\\b', place_name)\n",
    "        if state:\n",
    "            return state[0]\n",
    "    return place_name\n",
    "\n",
    "data_json[\"state\"] = data_json[\"place_name\"].map(extract_state)\n",
    "data_json[\"state\"] = data_json[\"state\"].map(state_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30860ae6",
   "metadata": {},
   "source": [
    "#### **Arredondar os índices `index_nsa` e `index_food`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d97e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json['index_nsa'] = data_json['index_nsa'].round(2)\n",
    "\n",
    "data_csv_fb['index_food'] = data_csv_fb['index_food'].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cd5d7ba",
   "metadata": {},
   "source": [
    "#### **Tratar a coluna `State`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05877e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'DC' with 'District of Columbia' in the 'state' column of the DataFrame\n",
    "data_csv_ps['state'] = data_csv_ps['state'].replace('DC', 'District of Columbia')\n",
    "\n",
    "data_csv_ps['state'] = data_csv_ps['state'].replace('US', 'United States')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0045c4a4",
   "metadata": {},
   "source": [
    "#### **Renomear colunas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47595164",
   "metadata": {},
   "source": [
    "Estas colunas são necessárias renomear para ser possível efetuar o merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a6a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_ps.rename(columns = {'all':'populationSize'}, inplace = True)\n",
    "\n",
    "data_json.rename(columns = {'yr':'year'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6b90e05",
   "metadata": {},
   "source": [
    "#### **Remover colunas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42be8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json.drop(['hpi_type', 'hpi_flavor', 'frequency', 'place_id', 'level'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e26410b",
   "metadata": {},
   "source": [
    "#### **Agrupar dataset `HPI` (json) por estado e ano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ead6e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map states with their IDs\n",
    "state_id_map = {\n",
    "    'United States': 0,\n",
    "    'Alabama': 1,\n",
    "    'Alaska': 2,\n",
    "    'Arizona': 4,\n",
    "    'Arkansas': 5,\n",
    "    'California': 6,\n",
    "    'Colorado': 8,\n",
    "    'Connecticut': 9,\n",
    "    'Delaware': 10,\n",
    "    'District of Columbia': 11,\n",
    "    'Florida': 12,\n",
    "    'Georgia': 13,\n",
    "    'Hawaii': 15,\n",
    "    'Idaho': 16,\n",
    "    'Illinois': 17,\n",
    "    'Indiana': 18,\n",
    "    'Iowa': 19,\n",
    "    'Kansas': 20,\n",
    "    'Kentucky': 21,\n",
    "    'Louisiana': 22,\n",
    "    'Maine': 23,\n",
    "    'Maryland': 24,\n",
    "    'Massachusetts': 25,\n",
    "    'Michigan': 26,\n",
    "    'Minnesota': 27,\n",
    "    'Mississippi': 28,\n",
    "    'Missouri': 29,\n",
    "    'Montana': 30,\n",
    "    'Nebraska': 31,\n",
    "    'Nevada': 32,\n",
    "    'New Hampshire': 33,\n",
    "    'New Jersey': 34,\n",
    "    'New Mexico': 35,\n",
    "    'New York': 36,\n",
    "    'North Carolina': 37,\n",
    "    'North Dakota': 38,\n",
    "    'Ohio': 39,\n",
    "    'Oklahoma': 40,\n",
    "    'Oregon': 41,\n",
    "    'Pennsylvania': 42,\n",
    "    'Rhode Island': 44,\n",
    "    'South Carolina': 45,\n",
    "    'South Dakota': 46,\n",
    "    'Tennessee': 47,\n",
    "    'Texas': 48,\n",
    "    'Utah': 49,\n",
    "    'Vermont': 50,\n",
    "    'Virginia': 51,\n",
    "    'Washington': 53,\n",
    "    'West Virginia': 54,\n",
    "    'Wisconsin': 55,\n",
    "    'Wyoming': 56,\n",
    "    'Puerto Rico': 72,\n",
    "    'Virgin Islands': 78,\n",
    "    'East North Central Division': 80,\n",
    "    'East South Central Division': 81,\n",
    "    'West North Central Division': 82,\n",
    "    'West South Central Division': 83,\n",
    "    'Middle Atlantic Division': 84,\n",
    "    'South Atlantic Division': 85,\n",
    "    'Pacific Division': 86,\n",
    "    'Mountain Division': 87,\n",
    "    'New England Division': 88\n",
    "}\n",
    "\n",
    "# Group the data by state and year and calculate the average of index values\n",
    "grouped_data = data_json.groupby(['state', 'year']).agg({'index_nsa': 'mean'})\n",
    "\n",
    "# Reset the index of the grouped DataFrame\n",
    "grouped_data = grouped_data.reset_index()\n",
    "\n",
    "# Round the 'index_nsa' column to 2 decimal places\n",
    "grouped_data['index_nsa'] = grouped_data['index_nsa'].round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dca13b0a",
   "metadata": {},
   "source": [
    "#### **Adicionar `state_id` ao dataset `HPI` (json) agrupado por estado e ano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e49d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'state_id' with the corresponding state ID using the dictionary\n",
    "grouped_data['state_id'] = grouped_data['state'].map(state_id_map)\n",
    "\n",
    "# Replace missing or invalid state IDs with a placeholder value, such as -1\n",
    "grouped_data['state_id'] = grouped_data['state_id'].fillna(-1).astype(int)\n",
    "\n",
    "# Reorder the columns to include 'state_id' as the first column\n",
    "grouped_data = grouped_data[['state_id', 'state', 'year', 'index_nsa']]\n",
    "\n",
    "grouped_data.rename(columns = {'index_nsa':'index_housing'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa54284b",
   "metadata": {},
   "source": [
    "#### **Visualizar resultados do tratamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd614eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar os resultados para novos ficheiros CSV\n",
    "data_csv_ps.to_csv('newPS.csv', index=False)\n",
    "data_csv_fb.to_csv('newFB.csv', index=False)\n",
    "grouped_data.to_csv('newHPI.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1843ef-ffd5-43be-9dba-e5b245f46a27",
   "metadata": {},
   "source": [
    "----\n",
    "## Converter para Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa22fa1f-7eef-4e81-a810-6fb64a310c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_population = data_csv_ps.to_parquet('../parquetFiles/data_ps.parquet')\n",
    "pq_housing = grouped_data.to_parquet('../parquetFiles/data_json.parquet')\n",
    "pq_food = data_csv_fb.to_parquet('../parquetFiles/data_fb.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "814f2464-dda7-4921-aaf3-98366a612c9c",
   "metadata": {},
   "source": [
    "## Realizar o Merge dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a3affdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Conexao ao MongoDB Atlas\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:2.4.0\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "pq_population = spark.read.format(\"parquet\").load('../parquetFiles/data_ps.parquet') # population size\n",
    "pq_housing = spark.read.format(\"parquet\").load('../parquetFiles/data_json.parquet') # habitacao\n",
    "pq_food = spark.read.format(\"parquet\").load('../parquetFiles/data_fb.parquet') # habitacao\n",
    "\n",
    "# Merge\n",
    "df_merged = pq_population.join(pq_housing, on=['state_id', 'state', 'year'], how='inner').join(pq_food, on=['year'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1d7c1f5",
   "metadata": {},
   "source": [
    "#### **Redução do tamanho do dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41f66040",
   "metadata": {},
   "source": [
    "- Remover colunas desnecessárias resultantes do merge\n",
    "- Remover valores nulos e duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "380020de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1836\n",
      "+----+--------+-------+-------+-------+-------+--------------+-------------+----------+\n",
      "|year|state_id|  state|   kids| adults|retired|populationSize|index_housing|index_food|\n",
      "+----+--------+-------+-------+-------+-------+--------------+-------------+----------+\n",
      "|1975|       1|Alabama|1961900|1333001| 383915|       3678816|        73.39|     60.19|\n",
      "|1976|       1|Alabama|1986831|1353185| 395123|       3735139|        77.07|     62.08|\n",
      "|1977|       1|Alabama|1987426|1385840| 407137|       3780403|         85.6|     65.77|\n",
      "|1978|       1|Alabama|1994049|1418210| 419579|       3831838|        72.34|     72.18|\n",
      "|1979|       1|Alabama|1988925|1444961| 432362|       3866248|        79.55|     79.93|\n",
      "|1980|       1|Alabama|1992985|1464940| 442443|       3900368|        81.44|     86.75|\n",
      "|1981|       1|Alabama|1984913|1483248| 450370|       3918531|        83.27|     93.52|\n",
      "|1982|       1|Alabama|1966316|1499944| 458969|       3925229|        84.02|      97.3|\n",
      "|1983|       1|Alabama|1950420|1517740| 465943|       3934103|        87.75|     99.48|\n",
      "|1984|       1|Alabama|1935127|1542166| 474533|       3951826|        88.01|    103.22|\n",
      "|1985|       1|Alabama|1922712|1567006| 482802|       3972520|        87.67|    105.58|\n",
      "|1986|       1|Alabama|1909095|1591729| 490738|       3991562|        91.27|    109.06|\n",
      "|1987|       1|Alabama|1893095|1622429| 499733|       4015257|        93.33|    113.55|\n",
      "|1988|       1|Alabama|1870972|1646005| 506871|       4023848|         93.1|    118.18|\n",
      "|1989|       1|Alabama|1846167|1669449| 514608|       4030224|         92.5|    124.91|\n",
      "|1990|       1|Alabama|1816851|1709813| 521844|       4048508|        91.83|    132.08|\n",
      "|1991|       1|Alabama|1817090|1744811| 529124|       4091025|        96.01|    136.77|\n",
      "|1992|       1|Alabama|1820211|1781853| 537205|       4139269|        98.67|    138.67|\n",
      "|1993|       1|Alabama|1826883|1820979| 545252|       4193114|       102.96|    141.61|\n",
      "|1994|       1|Alabama|1827342|1854573| 551050|       4232965|       106.48|    144.86|\n",
      "|1995|       1|Alabama|1829600|1876350| 556781|       4262731|       110.36|    148.87|\n",
      "|1996|       1|Alabama|1825378|1903556| 561469|       4290403|       114.96|    153.68|\n",
      "|1997|       1|Alabama|1829732|1925513| 565036|       4320281|       119.48|    157.74|\n",
      "|1998|       1|Alabama|1824926|1959224| 566887|       4351037|       125.17|     161.1|\n",
      "|1999|       1|Alabama|1812789|1989121| 567952|       4369862|       128.42|    164.55|\n",
      "|2000|       1|Alabama|1863196|2044564| 580880|       4452173|       131.55|    168.35|\n",
      "|2001|       1|Alabama|1855135|2064560| 583831|       4467634|       138.22|    173.58|\n",
      "|2002|       1|Alabama|1848250|2081805| 585605|       4480089|       142.18|    176.75|\n",
      "|2003|       1|Alabama|1850019|2100703| 590372|       4503491|       148.02|    180.54|\n",
      "|2004|       1|Alabama|1855460|2118550| 593826|       4530729|        153.8|    186.64|\n",
      "|2005|       1|Alabama|1865967|2140855| 602102|       4569805|       164.96|    191.18|\n",
      "|2006|       1|Alabama|1888725|2166668| 613080|       4628981|        178.3|    195.67|\n",
      "|2007|       1|Alabama|1902911|2188880| 622070|       4672840|       185.99|     203.3|\n",
      "|2008|       1|Alabama|1916862|2210783| 636944|       4718206|       186.46|    214.23|\n",
      "|2009|       1|Alabama|1923275|2231035| 649041|       4757938|       183.19|    218.25|\n",
      "|2010|       1|Alabama|1922313|2247946| 659822|       4785298|       175.22|    219.98|\n",
      "|1975|       2| Alaska| 230269| 137107|   8797|        376173|         65.6|     60.19|\n",
      "|1976|       2| Alaska| 245001| 146742|   9225|        400968|        73.59|     62.08|\n",
      "|1977|       2| Alaska| 244126| 149501|   9810|        403437|        78.26|     65.77|\n",
      "|1978|       2| Alaska| 243367| 151012|  10385|        404764|        74.97|     72.18|\n",
      "+----+--------+-------+-------+-------+-------+--------------+-------------+----------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_merged.drop(\"__index_level_0__\")\n",
    "entry_count = df_merged.count()\n",
    "print(\"Number of entries:\", entry_count)\n",
    "# Show the merged data\n",
    "df_merged.show(40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5976782d",
   "metadata": {},
   "source": [
    "----\n",
    "## **Armazenar os dados no MongoDB**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acaffa62",
   "metadata": {},
   "source": [
    "### Enviar os dados para o MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cbb5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"bigdata\"]\n",
    "collection = db[\"inflation\"]\n",
    "\n",
    "# Iterate over the rows of the DataFrame and insert into MongoDB\n",
    "for row in df_merged.collect():\n",
    "    document = row.asDict()\n",
    "    collection.insert_one(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
